# path to the image root folder containing multiple image folders: images1/, images2/ etc.
data_path: /app/alexw/Experements/Imaginova
# /app/alexw/Experements/Imaginova
# /app/alexw/Experements/Imaginova/sergey_blip_dataset_creation


# one or more (comma separated) .csv files, containing columns <paths> and <captions>
csv_list:
    # - /app/alexw/Experements/Imaginova/sergey_blip_dataset_creation/data/main_data/mj_RENEW_corrected.csv
    - /app/alexw/Experements/Imaginova/sergey_blip_dataset_creation/data/toy_data/images1.csv
    - /app/alexw/Experements/Imaginova/sergey_blip_dataset_creation/data/toy_data/images2.csv
    - /app/alexw/Experements/Imaginova/sergey_blip_dataset_creation/data/toy_data/images3.csv


# image crop box
crop_box: [0, 0, 1024, 1024]


# loads pretrained model and adds adapter if model.adapter.add_adapter is false,
# otherwise loads whole model from models.adapter.checkpoint.
# In both cases unfreezes various model's parts if required.
model:
    processor: "blip2-opt-2.7b"
    base_model:
        checkpoint: "blip2-opt-2.7b"
        unfreeze_language_model: false
        unfreeze_vision_model: false
        unfreeze_qformer: false
    adapter:
        add_adapter: false
        # loads weights and config from checkpoint
        load_from_checkpoint: false
        checkpoint: 
        lora_config:
            r: 16
            lora_alpha: 32
            lora_dropout: 0.05
            target_modules: ["q_proj", "k_proj"]
            bias: "none"


training:
    learning_rate: 5.0e-5
    n_epochs: 10
    batch_size: 1
    gradient_accumulation_steps: 1
    dataloader_workers: 32


# log_base_model=false used when base model is frozen to obtain lightweight checkpoints
logging:
    checkpoint_root: /app/alexw/Experements/Imaginova/sergey_blip_dataset_creation/checkpoints
    checkpoint_path: # updated in code
    
    log_base_model: true
    
    checkpoint_every_nth_epoch: 5
    wandb:
        enabled: false
        project: "BLIP2_FINETUNE"
     
    